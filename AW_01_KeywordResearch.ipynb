{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AW-01-KeywordResearch.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOvNLGVFo3mmtmKG/dSLZMW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juanignaciorey/Autocontent_SEO_with_AUTOML/blob/main/AW_01_KeywordResearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5RRjevRSKuR"
      },
      "source": [
        "keywords... piense en 5 a 6 cifras sin perder la calidad\n",
        "\n",
        "Tenemos que buscar la mayor cantidad de fuentes... sin perder el objetivo\n",
        "\n",
        "-  Google SERP\n",
        " - Meta Title, Desc\n",
        " - Google Also Ask\n",
        "\n",
        "-  Google Trends\n",
        " - \n",
        "\n",
        "- Google Sugest\n",
        "\n",
        "\n",
        "- Google Images\n",
        " - Google Pin badage\n",
        " - Analizar busquedas [relacionadas](https://www.google.com/search?q=descargar+gta+vice+city+espa%C3%B1ol&rlz=1C1CHBF_esAR932AR932&sxsrf=ALeKk01KrKANaiNvjzZaJH25ZiXnRYqEcA:1616707508424&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjj1vrlsMzvAhXuIbkGHRV8A9wQ_AUoAnoECAEQBA&biw=1920&bih=937)\n",
        "\n",
        "- Adwords\n",
        "\n",
        "- Translate - Para hacer canonical content\n",
        "\n",
        "- Keywords de top(competencia) del tema\n",
        "\n",
        "- Tambien podriamos usar blogs que hablen sobre los temas\n",
        " - Tipo Medium post\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hWq_b-BgDuu"
      },
      "source": [
        "### 1. Requeriment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bK1SGGngBfm"
      },
      "source": [
        "### Requerimientos\n",
        "!pip install pandas\n",
        "!pip install splinter\n",
        "!conda install splinter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxrPMTyGi7bQ"
      },
      "source": [
        "#@title Instalacion de paquetes\n",
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_3qzxcwgyxz",
        "outputId": "57bb4ead-3638-482c-dce8-a5f3fed199ee"
      },
      "source": [
        "#@title Configuracion de Selenium Browser\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "browser = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "browser.get(\"https://www.webite-url.com\")\n",
        "## https://stackoverflow.com/questions/56829470/selenium-google-colab-error-chromedriver-executable-needs-to-be-in-path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: use options instead of chrome_options\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sc5iVWHkEHg"
      },
      "source": [
        "width =   400 #@param {type:\"integer\"}\n",
        "height =   768 #@param {type:\"integer\"}\n",
        "# Rezising\n",
        "browser.set_window_size(width, height)\n",
        "browser.maximize_window()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luYQLIRJmZKA"
      },
      "source": [
        "#@title Instalacion de librerias\n",
        "import os\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAloZvtHmevN"
      },
      "source": [
        "#@title Drive Mount\n",
        "# conecta tu tiempo de ejecuci√≥n de Google Colab a tu Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDBTfbIsoOn-"
      },
      "source": [
        "### 2. Pilar Keywords\n",
        "\n",
        "Separa las palabras clave con ','"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R84LQt_BoTmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad256455-a489-4dc3-88a9-e147e3f9de6a"
      },
      "source": [
        "kwywords = 'machine learning,automl,npl' #@param {type:\"string\"}\n",
        "\n",
        "keywords = kwywords.split(',')\n",
        "keywords"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['machine learning', 'automl', 'npl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAENpXH3oBaP"
      },
      "source": [
        "### 3. Serp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2_zF2Ue2McC"
      },
      "source": [
        "try:\n",
        "    from googlesearch import search\n",
        "except ImportError: \n",
        "    print(\"No module named 'google' found\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "q89VmKptn_GG"
      },
      "source": [
        "# ref: https://www.geeksforgeeks.org/performing-google-search-using-python-code/\n",
        "# search(query, tld='com', lang='en', num=10, start=0, stop=None, pause=2.0)\n",
        "\n",
        "# tld stands for top level domain which means we want to search our result on google.com or google.in or some other domain.\n",
        "tld = 'com' #@param {type:\"string\"}\n",
        "# lang : lang stands for language. \n",
        "# https://www.labnol.org/code/19899-google-translate-languages\n",
        "lang = 'es' #@param ['es', 'en']\n",
        "# Number of results we want.\n",
        "num = 10 #@param {type:\"integer\"}\n",
        "# start : First result to retrieve.\n",
        "start = 0 \n",
        "# stop : Last result to retrieve. Use None to keep searching forever.\n",
        "stop = None\n",
        "# pause : Lapse to wait between HTTP requests. Lapse too short may cause Google to block your IP. Keeping significant lapse will make your program slow but its safe and better option.\n",
        "pause = 2.0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8J7hPLCZEQ4T",
        "outputId": "95cfa34d-dbd6-4c51-db64-9dc5ecafb3e5"
      },
      "source": [
        "for query in keywords:\n",
        "  # Return : Generator (iterator) that yields found URLs. If the stop parameter is None the iterator will loop forever.\n",
        "  for j in search(query, tld, lang, num, stop, pause):\n",
        "      print(j)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://en.wikipedia.org/wiki/Machine_learning\n",
            "https://en.wikipedia.org/wiki/Outline_of_machine_learning\n",
            "https://en.wikipedia.org/wiki/Online_machine_learning\n",
            "https://en.wikipedia.org/wiki/Machine_learning_control\n",
            "https://www.coursera.org/learn/machine-learning\n",
            "https://www.coursera.org/learn/machine-learning#about\n",
            "https://www.coursera.org/learn/machine-learning#instructors\n",
            "https://www.coursera.org/learn/machine-learning#syllabus\n",
            "https://www.sas.com/en_us/insights/analytics/machine-learning.html\n",
            "https://www.expert.ai/blog/machine-learning-definition/\n",
            "https://www.ibm.com/cloud/learn/machine-learning\n",
            "https://machinelearningmastery.com/types-of-learning-in-machine-learning/\n",
            "https://www.geeksforgeeks.org/machine-learning/\n",
            "https://www.technologyreview.com/2018/11/17/103781/what-is-machine-learning-we-drew-you-another-flowchart/\n",
            "https://searchenterpriseai.techtarget.com/definition/machine-learning-ML\n",
            "https://emerj.com/ai-glossary-terms/what-is-machine-learning/\n",
            "https://www.zdnet.com/article/what-is-machine-learning-everything-you-need-to-know/\n",
            "https://www.youtube.com/watch?v=ukzFI9rgwfU\n",
            "https://aws.amazon.com/machine-learning/\n",
            "https://www.deeplearning.ai/programs/\n",
            "https://azure.microsoft.com/en-us/services/machine-learning/\n",
            "https://www.investopedia.com/terms/m/machine-learning.asp\n",
            "https://www.ml.cmu.edu/\n",
            "https://www.mathworks.com/discovery/machine-learning.html\n",
            "https://royalsociety.org/topics-policy/projects/machine-learning/videos-and-background-information/\n",
            "https://www.springer.com/journal/10994\n",
            "https://christophm.github.io/interpretable-ml-book/\n",
            "https://www.udacity.com/course/machine-learning--ud262\n",
            "https://www.edx.org/course/machine-learning\n",
            "https://developer.apple.com/machine-learning/\n",
            "https://www.toptal.com/machine-learning/machine-learning-theory-an-introductory-primer\n",
            "https://www.udemy.com/course/machinelearning/\n",
            "https://www.udemy.com/topic/machine-learning/\n",
            "https://www.wired.com/tag/machine-learning/\n",
            "https://www.gartner.com/en/information-technology/glossary/machine-learning\n",
            "https://www.w3schools.com/python/python_ml_getting_started.asp\n",
            "https://www.techrepublic.com/article/machine-learning-the-smart-persons-guide/\n",
            "http://cs229.stanford.edu/\n",
            "https://online.stanford.edu/courses/cs229-machine-learning\n",
            "https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-867-machine-learning-fall-2006/\n",
            "https://deepai.org/machine-learning-glossary-and-terms/machine-learning\n",
            "https://xkcd.com/1838/\n",
            "https://www.oracle.com/data-science/machine-learning/what-is-machine-learning/\n",
            "https://archive.ics.uci.edu/\n",
            "https://www.classcentral.com/course/machine-learning-835\n",
            "https://enterprisersproject.com/article/2019/7/machine-learning-explained-plain-english\n",
            "https://arxiv.org/list/stat.ML/recent\n",
            "https://www.infoworld.com/article/3214424/what-is-machine-learning-intelligence-derived-from-data.html\n",
            "https://studio.azureml.net/\n",
            "https://www.netapp.com/artificial-intelligence/what-is-machine-learning/\n",
            "https://www.jmlr.org/\n",
            "https://www.datarobot.com/wiki/machine-learning/\n",
            "https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/\n",
            "https://www.nature.com/subjects/machine-learning\n",
            "https://towardsai.net/p/machine-learning/differences-between-ai-and-machine-learning-1255b182fc6\n",
            "https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471\n",
            "https://cleverdata.io/que-es-machine-learning-big-data/\n",
            "https://www.bbva.com/es/machine-learning-que-es-y-como-funciona/\n",
            "https://builtin.com/machine-learning\n",
            "https://scikit-learn.org/\n",
            "https://www.kaggle.com/learn/intro-to-machine-learning\n",
            "https://wiki.pathmind.com/ai-vs-machine-learning-vs-deep-learning\n",
            "https://www.simplilearn.com/tutorials/machine-learning-tutorial/what-is-machine-learning\n",
            "https://www.tensorflow.org/\n",
            "https://research.fb.com/category/machine-learning/\n",
            "https://www.zendesk.com/blog/machine-learning-and-deep-learning/\n",
            "https://www.wordstream.com/blog/ws/2017/07/28/machine-learning-applications\n",
            "https://www.springboard.com/courses/ai-machine-learning-career-track/\n",
            "https://www.forbes.com/sites/tomtaulli/2020/05/23/machine-learning-what-is-it-really-good-for/\n",
            "https://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html\n",
            "https://cran.r-project.org/view=MachineLearning\n",
            "https://vas3k.com/blog/machine_learning/\n",
            "https://www.frontiersin.org/articles/10.3389/fdata.2018.00006/full\n",
            "https://www.codecademy.com/learn/machine-learning\n",
            "https://towardsdatascience.com/machine-learning/home\n",
            "https://learn.g2.com/machine-learning\n",
            "https://online-learning.harvard.edu/course/data-science-machine-learning\n",
            "https://www.deeplearningbook.org/contents/ml.html\n",
            "https://www.splunk.com/en_us/software/splunk-enterprise/machine-learning.html\n",
            "https://www.bernardmarr.com/default.asp?contentID=1140\n",
            "https://www.dreyfus.org/machine-learning-in-the-chemical-sciences-and-engineering/\n",
            "https://softwareengineeringdaily.com/category/machine-learning/\n",
            "https://ml.gatech.edu/\n",
            "https://theconversation.com/us/topics/machine-learning-8332\n",
            "https://data-flair.training/blogs/machine-learning-tutorial/\n",
            "https://www.edureka.co/blog/what-is-machine-learning/\n",
            "https://www.packtpub.com/tech/machine-learning\n",
            "https://developer.android.com/ml\n",
            "https://www.britannica.com/technology/machine-learning\n",
            "https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/an-executives-guide-to-machine-learning\n",
            "https://theappsolutions.com/blog/development/machine-learning-algorithm-types/\n",
            "https://www.elastic.co/what-is/elasticsearch-machine-learning\n",
            "https://github.com/josephmisiti/awesome-machine-learning\n",
            "https://www.forcepoint.com/es/cyber-edu/machine-learning\n",
            "https://www.mygreatlearning.com/blog/what-is-machine-learning/\n",
            "https://www.brookings.edu/research/what-is-machine-learning/\n",
            "https://reference.wolfram.com/language/guide/MachineLearning.html\n",
            "http://www.r2d3.us/visual-intro-to-machine-learning-part-1/\n",
            "https://cognitiveclass.ai/courses/machine-learning-with-python/\n",
            "https://www.ted.com/topics/machine+learning\n",
            "https://www.pcmag.com/news/what-is-machine-learning\n",
            "https://www.intel.com/content/www/us/en/analytics/machine-learning/overview.html\n",
            "https://www.ironhack.com/en/data-analytics/what-is-machine-learning\n",
            "https://www.entrepreneur.com/topic/machine-learning\n",
            "https://unity.com/products/machine-learning-agents\n",
            "https://venturebeat.com/2021/03/23/major-flaws-found-in-machine-learning-for-covid-19-diagnosis/\n",
            "https://cedar.buffalo.edu/~srihari/CSE574/\n",
            "https://www.nytimes.com/2021/03/24/magazine/coffee-heart-machine-learning.html\n",
            "https://www.cloudera.com/products/machine-learning.html\n",
            "https://www.tutorialspoint.com/machine_learning_with_python/index.htm\n",
            "https://ml-cheatsheet.readthedocs.io/\n",
            "https://www.amazon.science/machine-learning\n",
            "https://icml.cc/\n",
            "https://paperswithcode.com/\n",
            "https://www.hpe.com/us/en/what-is/machine-learning.html\n",
            "https://martechtoday.com/how-machine-learning-works-150366\n",
            "https://realpython.com/tutorials/machine-learning/\n",
            "https://www.dice.com/jobs/q-Machine+learning-jobs\n",
            "https://elitedatascience.com/learn-machine-learning\n",
            "http://spark.apache.org/docs/latest/ml-guide.html\n",
            "https://lionbridge.ai/datasets/the-50-best-free-datasets-for-machine-learning/\n",
            "https://hbr.org/2020/09/how-to-win-with-machine-learning\n",
            "https://www.digitalocean.com/community/tutorials/an-introduction-to-machine-learning\n",
            "https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/\n",
            "https://machinelearningforkids.co.uk/\n",
            "https://www.reddit.com/r/machinelearning\n",
            "https://www.khanacademy.org/computing/ap-computer-science-principles/data-analysis-101/x2d2f703b37b450a3:machine-learning-and-bias/a/machine-learning-algorithms\n",
            "https://whimsical.com/machine-learning-roadmap-2020-CA7f3ykvXpnJ9Az32vYXva\n",
            "https://www.cs.ubc.ca/~murphyk/MLbook/\n",
            "https://www.datacamp.com/tracks/machine-learning-fundamentals-with-python\n",
            "https://www.amd.com/en/technologies/deep-machine-learning\n",
            "https://bigml.com/\n",
            "https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf\n",
            "https://sites.jamanetwork.com/machine-learning/\n",
            "https://www.trendmicro.com/vinfo/us/security/definition/machine-learning\n",
            "https://www.vertica.com/product/database-machine-learning/\n",
            "https://www.pnas.org/content/117/9/4571\n",
            "https://hunch.net/\n",
            "https://www.fda.gov/news-events/press-announcements/coronavirus-covid-19-update-fda-authorizes-first-machine-learning-based-screening-device-identify\n",
            "https://www.analyticsvidhya.com/blog/2021/03/everything-you-need-to-know-about-machine-learning/\n",
            "https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/\n",
            "https://www.blumeglobal.com/learning/machine-learning/\n",
            "https://www.dataversity.net/a-brief-history-of-machine-learning/\n",
            "https://www.businessinsider.com/what-is-machine-learning\n",
            "https://www.weforum.org/agenda/2021/03/responsible-machine-learning-that-protects-intellectual-property/\n",
            "https://twimlai.com/\n",
            "https://www.tableau.com/solutions/ai-analytics\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6dbe2ebad8d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# Return : Generator (iterator) that yields found URLs. If the stop parameter is None the iterator will loop forever.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googlesearch/__init__.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(query, tld, lang, tbs, safe, num, start, stop, domains, pause, tpe, country, extra_params, user_agent)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;31m# Request the Google Search results page.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;31m# Parse the response and get every anchored URL.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googlesearch/__init__.py\u001b[0m in \u001b[0;36mget_page\u001b[0;34m(url, user_agent)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'User-Agent'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mcookie_jar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cookie_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcookie_jar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mhttp_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mhttp_error_301\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_303\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_307\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_302\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 429: Too Many Requests"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGL8ub553Un8"
      },
      "source": [
        "# query : query string that we want to search for.\n",
        "query = \"download book * filetype:epub\"\n",
        "# Return : Generator (iterator) that yields found URLs. If the stop parameter is None the iterator will loop forever.\n",
        "for j in search(query, tld, lang, num, stop, pause):\n",
        "    print(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "cellView": "form",
        "id": "yf3X3sQkXuKQ",
        "outputId": "e779736f-710c-4f3f-ebdf-735a469fc8b5"
      },
      "source": [
        "#@title\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import datetime\n",
        "import platform\n",
        "from docopt import docopt\n",
        "from tqdm import tqdm \n",
        "from time import sleep\n",
        "import pandas as pd\n",
        "from pandas.io.json import json_normalize\n",
        "import logging\n",
        "from jinja2 import Environment, FileSystemLoader\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
        "\n",
        "''' \n",
        "Visualizza una barra di caricamento per mostrare l'attesa\n",
        "'''\n",
        "def sleepBar(seconds):\n",
        "    for i in tqdm(range(seconds)):\n",
        "        sleep(1)\n",
        "\n",
        "def prettyOutputName(filetype='html'):\n",
        "    _query = re.sub('\\s|\\\"|\\/|\\:|\\.','_', query.rstrip())\n",
        "    prettyname = _query\n",
        "    ts = time.time()\n",
        "    st = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y_%H-%M-%S-%f')\n",
        "    if filetype != 'html':\n",
        "        prettyname += \"_\" + st + \".\" + filetype\n",
        "    else:\n",
        "        prettyname += \"_\" + st + \".\" + filetype\n",
        "    return prettyname\n",
        "\n",
        "\n",
        "def initBrowser(headless=False):\n",
        "    if \"Windows\" in platform.system():\n",
        "        chrome_path = \"driver/chromedriver.exe\"\n",
        "    else:\n",
        "        chrome_path = \"driver/chromedriver\"\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument(\"--disable-features=NetworkService\")\n",
        "    if headless:\n",
        "        chrome_options.add_argument('headless')\n",
        "    return webdriver.Chrome(options=chrome_options,executable_path=chrome_path)\n",
        "\"\"\"\n",
        "Search on Google and returns the list of PAA questions in SERP.\n",
        "\"\"\"\n",
        "def newSearch(browser,query):\n",
        "    if lang== \"en\":\n",
        "        browser.get(\"https://www.google.com?hl=en\")\n",
        "        searchbox = browser.find_element_by_xpath(\"//input[@aria-label='Search']\")\n",
        "    else:\n",
        "        browser.get(\"https://www.google.com?hl=es\")\n",
        "        searchbox = browser.find_element_by_xpath(\"//input[@aria-label='Buscar']\")\n",
        "    \n",
        "    searchbox.send_keys(query)\n",
        "    sleepBar(2)\n",
        "    tabNTimes()\n",
        "    if lang== \"en\":\n",
        "        searchbtn = browser.find_elements_by_xpath(\"//input[@aria-label='Google Search']\")\n",
        "    else:\n",
        "    \tsearchbtn = browser.find_elements_by_xpath(\"//input[@aria-label='Buscar con Google']\")\n",
        "    try:\n",
        "        searchbtn[-1].click()\n",
        "    except:\n",
        "        searchbtn[0].click()\n",
        "    sleepBar(2)\n",
        "    paa = browser.find_elements_by_xpath(\"//span/following-sibling::div[contains(@class,'match-mod-horizontal-padding')]\")\n",
        "    hideGBar()\n",
        "    return paa\n",
        "\"\"\"\n",
        "Helper function that scroll into view the PAA questions element.\n",
        "\"\"\"\n",
        "def scrollToFeedback():\n",
        "    if lang == \"en\":\n",
        "        el = browser.find_element_by_xpath(\"//div[@class='kno-ftr']//div/following-sibling::a[text()='Feedback']\")\n",
        "    else:\n",
        "    \tel = browser.find_element_by_xpath(\"//div[@class='kno-ftr']//div/following-sibling::a[text()='Enviar comentarios']\")\n",
        "\n",
        "    actions = ActionChains(browser)\n",
        "    actions.move_to_element(el).perform()\n",
        "    browser.execute_script(\"arguments[0].scrollIntoView();\", el)\n",
        "    actions.send_keys(Keys.PAGE_UP).perform()\n",
        "    sleepBar(1)\n",
        "\"\"\"\n",
        "Accessibility helper: press TAB N times (default 2)\n",
        "\"\"\"\n",
        "def tabNTimes(N=2):\n",
        "    actions = ActionChains(browser) \n",
        "    for _ in range(N):\n",
        "        actions = actions.send_keys(Keys.TAB)\n",
        "    actions.perform()\n",
        "\n",
        "\"\"\"\n",
        "Click on questions N times\n",
        "\"\"\"\n",
        "def clickNTimes(el, n=1):\n",
        "    for i in range(n):\n",
        "        el.click()\n",
        "        logging.info(f\"clicking on ... {el.text}\")\n",
        "        sleepBar(1)\n",
        "        scrollToFeedback()\n",
        "        try:\n",
        "            el.find_element_by_xpath(\"//*[@aria-expanded='true']\").click()\n",
        "        except:\n",
        "            pass\n",
        "        sleepBar(1)\n",
        "\n",
        "\"\"\"\n",
        "Hide Google Bar to prevent ClickInterceptionError\n",
        "\"\"\"\n",
        "def hideGBar():\n",
        "\ttry:\n",
        "\t\tbrowser.execute_script('document.getElementById(\"searchform\").style.display = \"none\";')\n",
        "\texcept:\n",
        "\t\tpass\n",
        "\n",
        "\"\"\"\n",
        "Where the magic happens\n",
        "\"\"\"\n",
        "def crawlQuestions(start_paa, paa_list, initialSet, depth=0):\n",
        "    _tmp = createNode(paa_lst=paa_list, name=query, children=True)\n",
        "    \n",
        "    outer_cnt = 0\n",
        "    for q in start_paa:\n",
        "        scrollToFeedback()\n",
        "        if \"Dictionary\" in q.text:\n",
        "            continue\n",
        "        test = createNode(paa_lst=paa_list, n=0,\n",
        "                        name=q.text,\n",
        "                        parent=paa_list[0][\"name\"],\n",
        "                        children=True)\n",
        "        \n",
        "        clickNTimes(q)\n",
        "        new_q = showNewQuestions(initialSet)\n",
        "        for l, value in new_q.items():\n",
        "            sleepBar(1)\n",
        "            logging.info(f\"{l}, {value.text}\")\n",
        "            test1 = createNode(paa_lst=test[0][\"children\"][outer_cnt][\"children\"], \n",
        "                                name=value.text,\n",
        "                                parent=test[0][\"children\"][outer_cnt][\"name\"],\n",
        "                                children=True)\n",
        "            \n",
        "        initialSet = getCurrentSERP()\n",
        "        logging.info(f\"Current count: {outer_cnt}\")\n",
        "        outer_cnt += 1\n",
        "        if depth==1:\n",
        "            for i in range(depth):\n",
        "                currentQuestions = []\n",
        "                for i in initialSet.values():\n",
        "                    currentQuestions.append(i.text)\n",
        "                for i in paa_list[0][\"children\"]:\n",
        "                    for j in i[\"children\"]:\n",
        "                        parent = j['name']\n",
        "                        logging.info(parent)\n",
        "                        _tmpset = set()\n",
        "                        if parent in currentQuestions:\n",
        "                            try:\n",
        "                                if \"'\" in parent:\n",
        "                                    xpath_compiler = '//div[text()=\"' + parent + '\"]'\n",
        "                                else: \n",
        "                                    xpath_compiler= \"//div[text()='\" + parent + \"']\"\n",
        "                                question= browser.find_element_by_xpath(xpath_compiler)\n",
        "                            except NoSuchElementException:\n",
        "                                continue\n",
        "                            scrollToFeedback()\n",
        "                            sleepBar(1)\n",
        "                            clickNTimes(question)\n",
        "                            new_q = showNewQuestions(initialSet)\n",
        "                            for l, value in new_q.items():\n",
        "                                if value.text == parent:\n",
        "                                    continue\n",
        "                                j['children'].append({\"name\": value.text,\"parent\": parent})\n",
        "                                \n",
        "                            initialSet = getCurrentSERP()\n",
        "\n",
        "\"\"\"\n",
        "Get the current Result Page.\n",
        "Returns: \n",
        "    A list with newest questions.\n",
        "\"\"\"\n",
        "def getCurrentSERP():\n",
        "    _tmpset = {}\n",
        "    new_paa = browser.find_elements_by_xpath(\"//span/following-sibling::div[contains(@class,'match-mod-horizontal-padding')]\")\n",
        "    cnt= 0\n",
        "    for q in new_paa:\n",
        "        _tmpset.update({cnt:q})\n",
        "        cnt +=1\n",
        "    newInitialSet = _tmpset\n",
        "    return newInitialSet\n",
        "\n",
        "\"\"\"\n",
        "Shows new questions.\n",
        "Args:\n",
        "    intialSet (dict): The initial set in the PAA box.\n",
        "Returns:\n",
        "    list of questions with first 3-4 questions deleted (initalSet).\n",
        "\"\"\"\n",
        "def showNewQuestions(initialSet):\n",
        "    tmp = getCurrentSERP()\n",
        "    deletelist = [k for k, v in initialSet.items() if k in tmp and tmp[k] == v]\n",
        "    _tst = dict.copy(tmp)\n",
        "    for i,value in tmp.items():\n",
        "        if i in deletelist:\n",
        "            _tst.pop(i)\n",
        "    return _tst\n",
        "\n",
        "\"\"\"\n",
        "Create a new node in the list.\n",
        "Args:\n",
        "    paa_list_elements: list of web elements\n",
        "    n: index of 'children' list on a main node\n",
        "    name: node nome\n",
        "    parent: Indicates if the node has a parent. Default to null only for first level.\n",
        "    chilren: Indicates if the node has a children list. default false\n",
        "Returns:\n",
        "    list of questions with the current new node\n",
        "\"\"\"\n",
        "def createNode( n=-1, parent='null', children=False, name='',*, paa_lst):\n",
        "    logging.info(paa_lst)\n",
        "    if children:\n",
        "        _d = {\n",
        "        \"name\": name,\n",
        "        \"parent\": parent,\n",
        "        \"children\": [] \n",
        "        }\n",
        "    else:\n",
        "        _d = {\n",
        "        \"name\": name,\n",
        "        \"parent\": parent\n",
        "        }\n",
        "    if n!=-1:\n",
        "        logging.info(paa_lst[n][\"children\"])\n",
        "        paa_lst[n][\"children\"].append(_d)\n",
        "    else:\n",
        "        paa_lst.append(_d)\n",
        "    \n",
        "\n",
        "    return paa_lst\n",
        "\n",
        "\"\"\"\n",
        "This func takes in input JSON data and returns csv file.\n",
        "\"\"\"\n",
        "def flatten_csv(data,depth,prettyname):\n",
        "    try:\n",
        "        if depth == 0:\n",
        "            _ = json_normalize(data[0][\"children\"], 'children', ['name', 'parent',['children',]], record_prefix='inner.')\n",
        "            _.drop(columns=['children','inner.children','inner.parent'], inplace=True)\n",
        "            columnTitle = ['parent','name','inner.name']\n",
        "            _ = _.reindex(columns=columnTitle)\n",
        "            _.to_csv(prettyname,sep=\";\",encoding='utf-8')\n",
        "        elif depth == 1:\n",
        "            df = json_normalize(data[0][\"children\"], meta=['name','children','parent'], record_path=\"children\", record_prefix='inner.')\n",
        "            frames = [ json_normalize(i) for i in df['inner.children'] ]\n",
        "            result = pd.concat(frames)\n",
        "            result.rename(columns={\"name\": \"inner.inner.name\", \"parent\": \"inner.name\"}, inplace=True)\n",
        "            merge = pd.merge(df, result, how='left', on=\"inner.name\")\n",
        "            merge.drop(columns=['name'], inplace=True)\n",
        "            columnTitle = ['parent','inner.parent','inner.name','inner.inner.name']\n",
        "            merge = merge.reindex(columns=columnTitle)\n",
        "            merge = merge.drop_duplicates(subset='inner.inner.name', keep='first')\n",
        "            merge.to_csv(prettyname,sep=';',encoding='utf-8')\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"{e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "    args = docopt(usage)\n",
        "    print(args)\n",
        "    MAX_DEPTH = 1\n",
        "\n",
        "    if args['<depth>']:\n",
        "        depth = int(args['<depth>'])\n",
        "        if depth > MAX_DEPTH:\n",
        "            sys.exit(\"depth not allowed\")\n",
        "    else:\n",
        "        depth = 0\n",
        "\n",
        "    if args['en']:\n",
        "        lang = \"en\"\n",
        "    elif args['es']:\n",
        "        lang = \"es\"\n",
        "        \n",
        "\n",
        "\n",
        "    if args['<keyword>']:\n",
        "        if args['--headless']:\n",
        "            browser = initBrowser(True)\n",
        "        else:\n",
        "            browser = initBrowser()\n",
        "        query = args['<keyword>']\n",
        "        start_paa = newSearch(browser,query)\n",
        "\n",
        "        initialSet = {}\n",
        "        cnt= 0\n",
        "        for q in start_paa:\n",
        "            initialSet.update({cnt:q})\n",
        "            cnt +=1\n",
        "\n",
        "        paa_list = []\n",
        "\n",
        "        crawlQuestions(start_paa, paa_list, initialSet,depth)\n",
        "        treeData = 'var treeData = ' + json.dumps(paa_list) + ';'\n",
        "        \n",
        "        if paa_list[0]['children']:\n",
        "            root = os.path.dirname(os.path.abspath(__file__))\n",
        "            templates_dir = os.path.join(root, 'templates')\n",
        "            env = Environment( loader = FileSystemLoader(templates_dir) )\n",
        "            template = env.get_template('index.html')\n",
        "            filename = os.path.join(root, 'html', prettyOutputName())\n",
        "            with open(filename, 'w') as fh:\n",
        "                fh.write(template.render(\n",
        "                    treeData = treeData,\n",
        "                ))\n",
        "\n",
        "    if args['--csv']:\n",
        "        if paa_list[0]['children']:\n",
        "            _path = 'csv/'+prettyOutputName('csv')\n",
        "            flatten_csv(paa_list, depth, _path)\n",
        "\n",
        "    browser.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-5b959f107891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasicConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0mMAX_DEPTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'usage' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9rrL2opUh_2"
      },
      "source": [
        "# python gquestions.py query <keyword> (en|es) [depth <depth>] [--csv] [--headless]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "axcpECGMUwvQ",
        "outputId": "de03c62e-8c51-4349-a4a4-dbe3aa1b57d1"
      },
      "source": [
        "form = Slider()\n",
        "form._repr_html_()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n    <input type=\"range\" id=\"in140498676663184\"\\n     min=\"0\" max=\"100\" step=\"1\"\\n     value=\"0\" \\n     oninput=\"out140498676663184.value=in140498676663184.value\"\\n     onchange=\"\\n       google.colab.kernel.invokeFunction(\\n         \\'set_var\\', [140498676663184, this.valueAsNumber],\\n         {})\\n     \"\\n    >\\n    <output id=\"out140498676663184\">0</output>\\n    '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqRtCuHlFmpZ"
      },
      "source": [
        "### 4. Trends"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ii8CjgUFveM"
      },
      "source": [
        "from pytrends.request import TrendReq\n",
        "import pandas as pd\n",
        "import time\n",
        "startTime = time.time()\n",
        "pytrend = TrendReq(hl='en-GB', tz=360)\n",
        "\n",
        "dataset = []\n",
        "keywords = query_list\n",
        "\n",
        "for x in range(0,len(df2)):\n",
        "     keywords = [df2[x]]\n",
        "     pytrend.build_payload(\n",
        "     kw_list=keywords,\n",
        "     cat=0,\n",
        "     timeframe='2020-04-01 2020-05-01',\n",
        "     geo='GB')\n",
        "     data = pytrend.interest_over_time()\n",
        "     if not data.empty:\n",
        "          data = data.drop(labels=['isPartial'],axis='columns')\n",
        "          dataset.append(data)\n",
        "\n",
        "result = pd.concat(dataset, axis=1)\n",
        "result.to_csv('search_trends.csv')\n",
        "\n",
        "executionTime = (time.time() - startTime)\n",
        "print('Execution time in sec.: ' + str(executionTime))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH5v-Pwh4sL7"
      },
      "source": [
        "####  Ebooks\n",
        "\n",
        "##### Dorks\n",
        "name_of_ebook filetype:pdf\n",
        "name_of_ebook filetype:epub\n",
        "name_of_ebook filetype:mobi\n",
        "name_of_ebook filetype:txt\n",
        "intitle:index.of (epub)\n",
        "intitle:\"calibre library\" inurl:browse\n",
        "\n",
        "##### Webs\n",
        "https://www.overdrive.com/\n",
        "http://libgen.rs/\n",
        "https://www.gutenberg.org/\n",
        "https://centslessbooks.com/\n",
        "\n",
        "https://bookboon.com/es\n",
        "http://free-ebooks.net/\n",
        "https://freecomputerbooks.com/\n",
        "https://manybooks.net/\n",
        "\n",
        "##### Dispositivos\n",
        "Amazon kindle\n",
        "Audible\n",
        "Google Play books\n",
        "Kobo books"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upCCeMyj6RYT"
      },
      "source": [
        "nombres_posibles = []\n",
        "filetypes = ['pdf','epub','mobi','txt']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvHdxiIfoAXQ"
      },
      "source": [
        "### 2. Medium Posts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBLR9I4UlzRe"
      },
      "source": [
        "keyword = \"data%20science\"\n",
        "url = \"https://medium.com/search?q=\"+keyword\n",
        "print(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_zKCf9xmztO"
      },
      "source": [
        "wd.get(url)\n",
        "\n",
        "ScrollNumber = 50\n",
        "for i in range(1,ScrollNumber):\n",
        "    wd.execute_script(\"window.scrollTo(1,50000)\")\n",
        "    time.sleep(5)\n",
        "\n",
        "file = open('DS.html', 'w')\n",
        "file.write(wd.page_source)\n",
        "file.close()\n",
        "\n",
        "wd.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxMm0WFDm4kY"
      },
      "source": [
        "import urllib3\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "http=urllib3.PoolManager()\n",
        "\n",
        "def scrape():\n",
        "    data = open('DS.html','r')\n",
        "    soup = BeautifulSoup(data, 'html.parser')\n",
        "    for links in soup.find_all('div', {'class': 'postArticle-readMore'}):\n",
        "        link = links.find('a').get('href')\n",
        "        Blog_post(link)\n",
        "\n",
        "def Blog_post(link):\n",
        "    try:\n",
        "        print(link)\n",
        "        blogData = http.request('GET', link)\n",
        "        soup = BeautifulSoup(blogData.data, 'html.parser')\n",
        "        article = ''\n",
        "        tags = []\n",
        "        heading = soup.find('h1').text\n",
        "        for para in soup.find_all('p'):\n",
        "            p = para.text\n",
        "        p = p.strip('/u')\n",
        "        article = article + ' ' + p\n",
        "        for mtags in soup.find_all('a', {'class ': 'link u - baseColor‚Ää‚Äî‚Äälink'}):\n",
        "            tags.append(mtags.text)\n",
        "            # CreateDataFrame(list())\n",
        "            someList = [heading, article, tuple(tags)]\n",
        "            # print(someList[0])\n",
        "            CreateDataFrame(someList)\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ufaPbo9gaYb"
      },
      "source": [
        "search_bar.fill(\"serpstat.com\")\n",
        "# Now let's set up code to click the search button!\n",
        "search_button_xpath = '//*[@id=\"tsf\"]/div[2]/div[3]/center/input[1]'\n",
        "search_button = browser.find_by_xpath(search_button_xpath)[0]\n",
        "search_button.click()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORBAPU-eSMfR"
      },
      "source": [
        "### Google Also Ask\n",
        "\n",
        "### Google Sugest\n",
        "\n",
        "### Google Pin badage\n",
        "#### Analizar las primeras \n",
        "#### Analizar bbusquedas relacionadas desde ac√°\n",
        "##### https://www.google.com/search?q=descargar+gta+vice+city+espa%C3%B1ol&rlz=1C1CHBF_esAR932AR932&sxsrf=ALeKk01KrKANaiNvjzZaJH25ZiXnRYqEcA:1616707508424&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjj1vrlsMzvAhXuIbkGHRV8A9wQ_AUoAnoECAEQBA&biw=1920&bih=937\n",
        "\n",
        "### Adwords\n",
        "\n",
        "### Translate - Para hacer canonical content\n",
        "\n",
        "### Keywords de top(competencia) del tema\n",
        "\n",
        "### "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxUg5ZsZKhTC",
        "outputId": "7ed074c4-d139-4300-fa65-b77f70b191de"
      },
      "source": [
        "def is_valid(mediafire_url):\n",
        "    \"\"\"\n",
        "    Check is the link to mediafire is no broken\n",
        "    Example of a broken link: 'https://www.mediafire.com/file/null/oretresf-01.mp4/file'\n",
        "    \"\"\"\n",
        "    valid = True\n",
        "    link_parts = mediafire_url.split(\"/\")\n",
        "    if (link_parts[4] == \"null\"):\n",
        "        valid = False\n",
        "\n",
        "    return valid\n",
        "\n",
        "is_valid = is_valid(\"url\")\n",
        "is_valid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f3zLkqdQEVo"
      },
      "source": [
        "Deberiamos encontrar keywords desde distintas fuentes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUcsh5k3p6XO"
      },
      "source": [
        "!pip install tensorflow-gpu==1.13.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2B2zbAYp8mm"
      },
      "source": [
        "!pip install ludwig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzhYBMmtqAb4",
        "outputId": "78f8ce20-3944-4989-be13-632dcbeebc1e"
      },
      "source": [
        "!gsutil cp gs://dataset-uploader/bbc/bbc-text.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CommandException: Wrong number of arguments for \"cp\" command.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VGxTIhMqDKl"
      },
      "source": [
        "input_features:\n",
        "        name: text\n",
        "        type: text\n",
        "        level: word\n",
        "        encoder: parallel_cnn\n",
        "\n",
        "output_features:\n",
        "        name: category\n",
        "        type: category"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5963IDdri1c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4myrpu-ZqhZg"
      },
      "source": [
        "!ludwig experiment \\\n",
        "  --data_csv bbc-text.csv\\\n",
        "  --model_definition_file model_definition.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GVnbeBpqp5m"
      },
      "source": [
        "#https://github.com/uber/ludwig/issues/267#issuecomment-497304317\n",
        "from ludwig import visualize\n",
        "visualize.learning_curves(['/content/results/experiment_run_0/training_statistics.json'],None)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}